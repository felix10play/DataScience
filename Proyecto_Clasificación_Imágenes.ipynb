{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f430cc82-0e07-4345-b40c-3a1e22de51ff",
   "metadata": {
    "id": "f430cc82-0e07-4345-b40c-3a1e22de51ff"
   },
   "source": [
    "<h1><font color=\"#113D68\" size=5>Redes neuronales convolucionales</font></h1>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#113D68\" size=6>Caso Práctico: análisis de un problema de clasificación de imágenes con Deep Learning</font></h1>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font size=3>Daniel González</font><br>\n",
    "<font size=3>IEBS</font>\n",
    "</div>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba54fa-f73e-40c2-9883-b4186be0a564",
   "metadata": {
    "id": "1dba54fa-f73e-40c2-9883-b4186be0a564"
   },
   "source": [
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [Caso práctico](#section1)\n",
    "    - [Parte obligatoria](#section1.1)\n",
    "    - [Parte opcional](#section1.2)\n",
    "    - [Objetivos](#section1.3)\n",
    "    - [Criterios de entrega](#section1.4)\n",
    "    - [Temporalización](#section1.5)\n",
    "* [Flickr Style dataset](#section2)\n",
    "* [Red convolucional desde 0](#section3)\n",
    "    - [Ejercicio 1](#section3.1)\n",
    "    - [Ejercicio 2](#section3.2)\n",
    "* [Red pre-entrenada (InceptionV3)](#section4)\n",
    "    - [Ejercicio 3](#section4.1)\n",
    "    - [Ejercicio 4](#section4.2)\n",
    "    - [Ejercicio 5](#section4.3)\n",
    "    - [Ejercicio 6](#section4.3)\n",
    "    - [Ejercicio 7](#section4.4)\n",
    "    - [Ejercicio 8](#section4.5)\n",
    "* [Red opcional](#section5)\n",
    "    - [Ejercicio 7](#section5.1)\n",
    "* [¿Cuál es el mejor modelo?](#section6)\n",
    "    - [Ejercicio 8](#section6.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063b23e-4fb9-42ea-b062-48b9657a0acd",
   "metadata": {
    "id": "e063b23e-4fb9-42ea-b062-48b9657a0acd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Para mostrar gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Anaconda fixing problem\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Establecemos una semilla para numpy y tensorflow para poder reproducir la ejecución y los resultados\n",
    "seed = 101\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e317bcf-3b1a-45ca-8505-8472b270353f",
   "metadata": {
    "id": "6e317bcf-3b1a-45ca-8505-8472b270353f",
    "tags": []
   },
   "source": [
    "# <font color=\"#004D7F\" size=5>Caso práctico</font>\n",
    "\n",
    "El objetivo de este caso práctico es simular como se haría un análisis completo de un problema de clasificación de imágenes para resolverlo con Deep Learning. Nos pondremos en la piel de un *data scientist* dedicado a analizar y crear modelos de Deep Learning para pasarlos a producción y ser desplegados en una aplicación.\n",
    "\n",
    "**Destacar que este caso práctico es la continuación de la actividad de la semana 2. En la actividad de la semana 2 utilizamos el modelo pre-entrendo de InceptionV3 y ahora vamos a realizar más experimentos usando redes convolucionales diseñadas por vosotros.**\n",
    "\n",
    "Imaginemos que tenemos un dataset completo que queremos explotar, nuestra labor será coger este dataset (Flickr Style dataset) y desde 0 intentar llegar a conseguir un modelo que tenga un buen rendimiento ajustándolo poco a poco como hemos visto en clase. Por lo que tendremos que entrerar distintas redes y comparar los resultados que obtengamos en cada experimento para ver cual es mejor.\n",
    "\n",
    "Cada experimento que tendremos que realizar estará bien definido, la red que deberéis crear y entrenar será proporcinada por lo que solamente tendréis que crear la red que se nos indica con TensorFlow y realizar el entrenamiento de la misma.\n",
    "\n",
    "## <font color=\"#004D7F\" size=4>Parte obligatoria</font>\n",
    "\n",
    "Será obligatorio realizar cada uno de los ejercicios que están definidos. En cada ejercicio está definida la red que se tiene que crear y la configuración con la que se tiene que entrenar, por lo que solamente tendréis que pasar esa definición a código con TensorFlow.\n",
    "\n",
    "Para tener una buena práctica en la realización de este caso práctico se ofrecen esta recomendaciones:\n",
    "\n",
    "- Utiliza correctamente el sistema de celdas de jupyter. La libreta está realizada de tal forma que solo tendréis que completar las celdas que se indican, ya sea con código o con texto en markdown. Se recomienda rellenar solamente las celdas indicadas para que quede un informe limpio y fácil de seguir. Si fuera necesario incluir más celdas por cualquier motivo se puede hacer pero realizarlo con cuidado para no ensuciar demasiado la libreta.\n",
    "<br><br>\n",
    "- Las redes que tendréis que crear en cada experimento son las vistas en clase, por lo que os podéis inspirar en los ejemplos vistos en los tutoriales. Os recomiendo que no copiéis y peguéis código tal cual, sino que lo escribáis por vuestra cuenta y entendáis lo que estáis haciendo en cada momento. Tomaros el tiempo que haga falta para entender cada paso.\n",
    "<br><br>\n",
    "- Comprueba que todo se ejecuta correctamente antes de enviar tu trabajo. La mejor forma de enviarlo es exportando la libreta a pdf o html para enviarla en un formato más profesional.\n",
    "\n",
    "## <font color=\"#004D7F\" size=4>Parte opcional</font>\n",
    "La parte opcional es el penúltimo ejercicio donde tendréis volver a aplicar la técnica de _fine-tuning_ eligiendo la red pre-entrenada que vosotros queráis y añadiendo las capas que vosotros elijáis.\n",
    "\n",
    "## <font color=\"#004D7F\" size=4>Objetivos</font>\n",
    "* Cargar y entender los datos del dataset Flickr Style con los que se trabajarán.\n",
    "* Crear cada una de las redes indicadas en los experimentos.\n",
    "* Entrenar cada una de las redes creadas en los experimentos.\n",
    "* Entender los resultados obtenidos en cada entrenamiento.\n",
    "\n",
    "## <font color=\"#004D7F\" size=4>Criterios de entrega</font>\n",
    "Se deberá entregar una libreta de jupyter, aunque se agradecerá que el formato entregado se html o pdf, el trabajo debe estar autocontenido, incluyendo código y texto explicativo para cada sección. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f976134-6498-4f42-9bde-dafa9e86a9c2",
   "metadata": {
    "id": "0f976134-6498-4f42-9bde-dafa9e86a9c2"
   },
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Flickr Style dataset</font>\n",
    "\n",
    "Este dataset es el que hemos visto en clase y con el que trabajaremos en el caso práctico. Para refrescarlo, es un dataset que contiene imágenes en color donde queremos clasificar cada imagen según el estilo fotográfico al que pertenece.\n",
    "\n",
    "El dataset de de imágenes Flickr Style tiene las siguintes características:\n",
    "- Imágenes de 5 tipos de estilo: Detailed, Pastel, Melancholy, Noir y HDR.\n",
    "- Imágenes en color, es decir, cada pixel tiene 3 valores entre 0 y 255, esos valores corresponden a los valores de RGB (Red, Green, Blue).\n",
    "- Imágenes de diferentes tamaños, por lo que tendremos que redimensionarlas al mismo tamaño todas antes de usarlas en nuestro modelo.\n",
    "- 2.000 imágenes en total para el entrenamiento y para el test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce9fa2-dbb4-490b-8f1e-ba094500d02f",
   "metadata": {
    "id": "64ce9fa2-dbb4-490b-8f1e-ba094500d02f"
   },
   "source": [
    "#### **Imporante!!! Solo ejecutar esta celda una sola vez para descargar los datos, no ejecutarlas si ya tenéis los datos descargados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb48ce-c97d-4c67-bf0d-c62ba8d082e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebfb48ce-c97d-4c67-bf0d-c62ba8d082e2",
    "outputId": "d2070b83-b313-4d2a-b24c-3fd6fee8c09e"
   },
   "outputs": [],
   "source": [
    "!wget 'https://www.dropbox.com/s/ln92e9givhgzugr/flickr_style.zip?dl=0' -O flickr_style.zip\n",
    "!unzip -q flickr_style.zip\n",
    "!mkdir data\n",
    "!mv flickr_style data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76bc09-a584-4048-b487-188d881cdafc",
   "metadata": {
    "id": "2b76bc09-a584-4048-b487-188d881cdafc"
   },
   "source": [
    "Vamos a cargar los datos de las labels y los datos de las rutas de las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b3921-e5d8-4720-a560-cd246d940fd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c11b3921-e5d8-4720-a560-cd246d940fd8",
    "outputId": "0ff28a74-47e7-4c52-f39a-a5a8bc7483bc"
   },
   "outputs": [],
   "source": [
    "# obtenemos el nombre de las primeras etiquetas seleccionadas\n",
    "style_label_file = 'data/flickr_style/style_names.txt'\n",
    "style_labels = list(np.loadtxt(style_label_file, str, delimiter='\\n'))\n",
    "style_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e4c8a-ae07-4edd-8b61-622a9b0dba1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "b90e4c8a-ae07-4edd-8b61-622a9b0dba1d",
    "outputId": "e44a5f34-0d2f-40e9-acee-157a206c3347"
   },
   "outputs": [],
   "source": [
    "# cargamos los datos de train\n",
    "train_frame = pd.read_csv('data/flickr_style/train.txt', sep=\" \", header=None)\n",
    "train_frame.columns = ['files','labels_idx']\n",
    "train_frame['labels'] = train_frame['labels_idx'].map({i:j for i,j in enumerate(style_labels)})\n",
    "\n",
    "train_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd427498-44c9-4928-bc98-5801e1cefc78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fd427498-44c9-4928-bc98-5801e1cefc78",
    "outputId": "55539b3d-bb33-439d-e253-05548617963f"
   },
   "outputs": [],
   "source": [
    "# cargamos los datos de test\n",
    "test_frame = pd.read_csv('data/flickr_style/test.txt', sep=\" \", header=None)\n",
    "test_frame.columns = ['files','labels_idx']\n",
    "test_frame['labels'] = test_frame['labels_idx'].map({i:j for i,j in enumerate(style_labels)})\n",
    "\n",
    "test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7233535-cd0b-4eaf-bd34-6a9a4646480c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f7233535-cd0b-4eaf-bd34-6a9a4646480c",
    "outputId": "6bfe8bc2-ffac-4eed-8cb5-f3a59d9001ff"
   },
   "outputs": [],
   "source": [
    "# Mostramos 5 imágenes de cada clase.\n",
    "plot_n_images = 5\n",
    "fig = plt.figure(figsize=(20, 25))\n",
    "\n",
    "np.random.seed(1000)\n",
    "for i in range(0,5):\n",
    "    select_frame = train_frame[train_frame['labels_idx']==i]\n",
    "    for j in range(0,plot_n_images):\n",
    "        aux_index = np.random.choice(select_frame.index)\n",
    "        fig_i=fig.add_subplot(plot_n_images,5,j*5+i+1)\n",
    "        fig_i.imshow(plt.imread(train_frame['files'][aux_index]))\n",
    "        \n",
    "        fig_i.set_xticks(())\n",
    "        fig_i.set_yticks(())\n",
    "        \n",
    "    fig_i.set_xlabel('Class %s' % style_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f2675-9333-4c42-aa8e-181b3e7c402d",
   "metadata": {
    "id": "3b0f2675-9333-4c42-aa8e-181b3e7c402d"
   },
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Red convolucional desde 0</font>\n",
    "\n",
    "Los primeros experimentos que vamos a realizar será utilizando redes que creemos nosotros mismos. Para ello vamos a tener que transformar las imágense al igual que hicimos en clase, pero esta vez solamente tendremos que realizar estos pasos:\n",
    "\n",
    "1. Cargar las imágenes\n",
    "2. Redimensionar todoas las imágenes para tener el mismo tamaño. Usaremos un tamaño de `(150, 150, 3)`.\n",
    "\n",
    "Como véis, al usar nuestras redes desde 0 no será necesario usar la función `preprocess_input` que tenemos que usar al usar una red pre-entrenada.\n",
    "\n",
    "La función para transformar las imágenes sería la siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42210c-f696-4103-98ee-72e1ce4e059b",
   "metadata": {
    "id": "5d42210c-f696-4103-98ee-72e1ce4e059b"
   },
   "outputs": [],
   "source": [
    "def load_img(img_path):\n",
    "    # cargamos y redimensionamos una imágen\n",
    "    img = tf.keras.utils.load_img(\n",
    "        img_path,\n",
    "        target_size=(150, 150, 3) \n",
    "    )\n",
    "    \n",
    "    # cambiamos el tipo imagen a un numpy.array\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    \n",
    "    # normalizamos los valores entre 0 y 1\n",
    "    return img_array / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ae51b-f8d6-4a5d-9421-3d3c0677e551",
   "metadata": {
    "id": "8b5ae51b-f8d6-4a5d-9421-3d3c0677e551"
   },
   "source": [
    "Ahora vamos a cargar las imágenes para poder entrenar nuestras redes convolucionales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b8c8c-3bc3-4b42-92a9-cc902b5774ff",
   "metadata": {
    "id": "955b8c8c-3bc3-4b42-92a9-cc902b5774ff"
   },
   "outputs": [],
   "source": [
    "# cargamos las imágenes ya transformadas\n",
    "x_train = np.array([load_img(img_path) for img_path in train_frame['files']])\n",
    "x_test = np.array([load_img(img_path) for img_path in test_frame['files']])\n",
    "\n",
    "# cargamos las clases de cada imagen\n",
    "y_train = train_frame['labels_idx']\n",
    "y_test = test_frame['labels_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3bd40-fe1e-4f8a-add4-0edc9033a9a9",
   "metadata": {
    "id": "13e3bd40-fe1e-4f8a-add4-0edc9033a9a9"
   },
   "source": [
    "<a id=\"section3.1\"></a>\n",
    "### <font color=\"#004D7F\" size=4>Ejercicio 1</font>\n",
    "\n",
    "Crear una red con la siguiente configuración y entrénala:\n",
    "\n",
    "Arquitectura de la red:\n",
    "\n",
    "- Capa convolucional `Conv2D` con 16 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU* y con entrada `(150,150,3)`\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa de aplanado `Flatten`.\n",
    "- Capa densa `Dense` con 64 neuronas y función de activación _ReLU_.\n",
    "- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.\n",
    "- Capa de salida densa `Dense` con 5 neuronas y función de activación _Softmax_.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "\n",
    "- Optimizador: Adam con factor de entrenamiento 0.001\n",
    "- Función de error: `sparce_categorical_crossentropy`.\n",
    "- Métricas: `accuracy`.\n",
    "- Número de _epochs_: 10\n",
    "- Validation split: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2a7db-4217-4166-8848-a63e53df9f5b",
   "metadata": {
    "id": "bdd2a7db-4217-4166-8848-a63e53df9f5b"
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f511d20-41ed-4c3f-879c-001ac22935be",
   "metadata": {
    "id": "8f511d20-41ed-4c3f-879c-001ac22935be"
   },
   "source": [
    "Evalua el modelo con el conjunto de test y muestra en una gráfica la evolución del entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5f2cf-448d-4829-ab2d-d1e90bd4e83e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1e5f2cf-448d-4829-ab2d-d1e90bd4e83e",
    "outputId": "7b3bfdc5-146b-45c1-b470-9ce0291a58dc"
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd526aa-cc08-45f8-babc-b4a5309cd49b",
   "metadata": {
    "id": "cdd526aa-cc08-45f8-babc-b4a5309cd49b"
   },
   "source": [
    "Escribe un pequeño texto sacando conclusiones de los resultado obtenidos:\n",
    "\n",
    "COMPLETAR: ESCRIBE AQUÍ TU TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11e8b2-f4d9-4080-9751-dd928e0e9f63",
   "metadata": {
    "id": "dd11e8b2-f4d9-4080-9751-dd928e0e9f63"
   },
   "source": [
    "<a id=\"section3.2\"></a>\n",
    "### <font color=\"#004D7F\" size=4>Ejercicio 2</font>\n",
    "\n",
    "Crear una red con la siguiente configuración y entrénala:\n",
    "\n",
    "Arquitectura de la red:\n",
    "\n",
    "- Capa convolucional `Conv2D` con 64 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU* y con entrada `(150,150,3)`\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa convolucional `Conv2D` con 32 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU*\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa convolucional `Conv2D` con 32 filtros/kernels de tamaño `(3,3)`, padding con relleno, activación *ReLU*\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa de aplanado `Flatten`.\n",
    "- Capa densa `Dense` con 64 neuronas y función de activación _ReLU_.\n",
    "- Capa `Dropout` con un valor de `0.75`.\n",
    "- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.\n",
    "- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.\n",
    "- Capa `Dropout` con un valor de `0.6`.\n",
    "- Capa de salida densa `Dense` con 10 neuronas y función de activación _Softmax_.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "\n",
    "- Optimizador: Adam con factor de entrenamiento 0.001\n",
    "- Función de error: `sparce_categorical_crossentropy`.\n",
    "- Métricas: `accuracy`.\n",
    "- Número de _epochs_: 50\n",
    "- Validation split: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d2c51-b3ce-4bb6-ba2e-d9c6248c784f",
   "metadata": {
    "id": "8f4d2c51-b3ce-4bb6-ba2e-d9c6248c784f"
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0579588-1ac4-4ad8-ac29-388bed21ce44",
   "metadata": {
    "id": "b0579588-1ac4-4ad8-ac29-388bed21ce44"
   },
   "source": [
    "Evalua el modelo con el conjunto de test y muestra en una gráfica la evolución del entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bcac7-6934-492a-9971-2e5b0bd4e650",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d0bcac7-6934-492a-9971-2e5b0bd4e650",
    "outputId": "5bd77e7c-393f-4da0-c48e-60e8217eeb0c"
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37827b8f-25b4-4660-8436-677874299b7f",
   "metadata": {
    "id": "37827b8f-25b4-4660-8436-677874299b7f"
   },
   "source": [
    "Escribe un pequeño texto sacando conclusiones de los resultado obtenidos:\n",
    "\n",
    "COMPLETAR: ESCRIBE AQUÍ TU TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a553504-0f17-4e44-936f-00df93fd0e10",
   "metadata": {
    "id": "1a553504-0f17-4e44-936f-00df93fd0e10"
   },
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Red pre-entrenada (InceptionV3)</font>\n",
    "\n",
    "Ahora vamos a realizar experimento usando la técnica de _fine-tuning_ y utilizando el modelo pre-entrenado de [_InceptionV3_](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3).\n",
    "\n",
    "Los ejercicios siguientes podéis observar que son los mismos ejercicios de la actividad de la semana 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d008e-dca0-4378-8057-5ca674372c83",
   "metadata": {
    "id": "ca7d008e-dca0-4378-8057-5ca674372c83"
   },
   "source": [
    "<a id=\"section4.1\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 3: preprocesamiento de las imágenes</font>\n",
    "Como vamos a usar un modelo pre-entreando tenemos que definir la función que nos transforme las imágenes a utilizar. Como hemos visto en clase, para utilizar las imágenes usando un modelo pre-entrenado es necesario realizar una transformación sobre las imágenes que vamos a utilizar, es decir, tenemos que:\n",
    "\n",
    "1. Cargar las imágenes\n",
    "2. Redimensionarlas\n",
    "3. Usar la función de `preprocess_input` del modelo pre-entrenado que vamos a utilizar.\n",
    "\n",
    "En este caso vamos a utilizar otro modelo pre-entrado entre los que están disponibles en `tf.keras`, esta vez vamos a usar el modelo de _InceptionV3_, um modelo muy popular y usando frecuentemente. Podéis ver toda la información de este modelo [aquí](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3). Este modelo utilizar un tamaño de imagen de _**(299, 299, 3)**_, por lo que tendrás que usar este tamaño en el redimensionamiento.\n",
    "\n",
    "Como hemos hecho en clase, define una función que se llame `load_img_inceptionv3(img_path)` a la cual le pasamos la ruta donde está alojada una imagen y le realiza todas las transformación necesarias para poder se utilizada luego en el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef42b9-902e-4e37-81e0-14fb10a2f3ea",
   "metadata": {
    "id": "f5ef42b9-902e-4e37-81e0-14fb10a2f3ea"
   },
   "outputs": [],
   "source": [
    "def load_img_inceptionv3(img_path):\n",
    "    # Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eccbe3-64a5-4366-9b33-9cc9e609a09a",
   "metadata": {
    "id": "e2eccbe3-64a5-4366-9b33-9cc9e609a09a"
   },
   "source": [
    "**Test**: Puedes probar esta función con el siguiente test, cuando la tengas definida ejecuta la siguiente celda y te debería dar como resultado:\n",
    "\n",
    "```python\n",
    "-0.5529412\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6af9ab-a02c-4d7a-8905-c5e536eb67ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a6af9ab-a02c-4d7a-8905-c5e536eb67ff",
    "outputId": "f4d2045d-7471-4162-b6e8-d6d2876678fd"
   },
   "outputs": [],
   "source": [
    "img = load_img_inceptionv3('data/flickr_style/images/2216312257_2ba4af8439.jpg')\n",
    "img[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff8d3f-0b6b-447c-9368-743c8390fcbb",
   "metadata": {
    "id": "0cff8d3f-0b6b-447c-9368-743c8390fcbb"
   },
   "source": [
    "<a id=\"section4.2\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 4: aplicar el preprocesamiento a todas las imágenes</font>\n",
    "Una vez tenemos definida nuestra función de para transformar las imágenes, aplíca la transformación tanto al conjunto de train como al conjunto de test como hemos visto en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49128e76-639b-4ce5-9688-efb0a7607d49",
   "metadata": {
    "id": "49128e76-639b-4ce5-9688-efb0a7607d49"
   },
   "outputs": [],
   "source": [
    "# cargamos las imágenes ya transformadas\n",
    "x_train = ...\n",
    "x_test = ...\n",
    "\n",
    "# cargamos las clases de cada imagen\n",
    "y_train = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc7e55-c715-4734-8b1f-ca937387a32b",
   "metadata": {
    "id": "c3cc7e55-c715-4734-8b1f-ca937387a32b"
   },
   "source": [
    "**Test**: Puedes probar si lo has hecho correctamente con el siguiente test, cuando hayas terminado ejecuta la siguiente celda y te debería dar como resultado:\n",
    "\n",
    "```python\n",
    "(array([-0.5529412, -0.5529412, -0.5372549], dtype=float32), 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026327b1-c47f-4064-91e6-6d86314caa26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "026327b1-c47f-4064-91e6-6d86314caa26",
    "outputId": "637165cf-cd50-4e5c-a436-1368650e3893"
   },
   "outputs": [],
   "source": [
    "x_train[0,0,0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469613ce-71de-43d4-8780-40e6b852c205",
   "metadata": {
    "id": "469613ce-71de-43d4-8780-40e6b852c205",
    "tags": []
   },
   "source": [
    "<a id=\"section4.3\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 5: cargar el modelo pre-entrenado InceptionV3</font>\n",
    "Una vez tenemos los datos listos, vamos a cargar el modelo pre-entrenado de [_InceptionV3_](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3).\n",
    "\n",
    "Como vamos a aplicar _fine-tuning_ recuerda usar los siguientes parámetros:\n",
    "- `input_shape=(299, 299, 3)`\n",
    "- `include_top=False`\n",
    "- `pooling='avg'`\n",
    "\n",
    "Además tienes que congelar todas las capas para que no se entrenen todas, recureda que solo queremos entrenar las últimas que añadamos nosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b91db0-9c11-4fc4-bd1b-65b512d6fdec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14b91db0-9c11-4fc4-bd1b-65b512d6fdec",
    "outputId": "2ec21832-33fc-499b-d790-c48782b0f32b"
   },
   "outputs": [],
   "source": [
    "base_model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5fc95-2fff-4bb2-a04b-afcce1a050c3",
   "metadata": {
    "id": "f3b5fc95-2fff-4bb2-a04b-afcce1a050c3"
   },
   "source": [
    "**Test**: Puedes probar si lo has hecho correctamente con el siguiente test, cuando hayas terminado ejecuta la siguiente celda y te debería dar como resultado:\n",
    "\n",
    "```python\n",
    "[<keras.layers.merge.Concatenate at **************>,\n",
    " <keras.layers.pooling.GlobalAveragePooling2D at **************>]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337613a-7d7b-4e4f-8157-a7051d8925b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9337613a-7d7b-4e4f-8157-a7051d8925b1",
    "outputId": "b6292410-7c38-430e-d795-2aa2119f6064"
   },
   "outputs": [],
   "source": [
    "base_model.layers[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d90d0-c700-47df-8eb0-a145e11bda3c",
   "metadata": {
    "id": "ab5d90d0-c700-47df-8eb0-a145e11bda3c",
    "tags": []
   },
   "source": [
    "<a id=\"section4.4\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 6: añadir capas al modelo (_fine-tuning_)</font>\n",
    "Una vez tenemos nuestro modelo base, vamos a añadir capas densas al final para entrenarlas y que el modelo se ajuste a nuestros datos.\n",
    "\n",
    "Añade las siguientes capas al modelo base cargado:\n",
    "- Capa Dropout con un valor de 0.60.\n",
    "- Capa Densa de 128 neuronas y función de activación `relu`.\n",
    "- Capa Dropout con un valor de 0.4.\n",
    "- Capa Densa de salida con 5 neuronas y función de activación `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f8bc7-8826-45e8-b6b0-adeafed34bed",
   "metadata": {
    "id": "b08f8bc7-8826-45e8-b6b0-adeafed34bed"
   },
   "outputs": [],
   "source": [
    "# Completar\n",
    "\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5283037-4dc7-4bf5-9c70-20979c2608ac",
   "metadata": {
    "id": "c5283037-4dc7-4bf5-9c70-20979c2608ac"
   },
   "source": [
    "**Test**: Puedes probar si lo has hecho correctamente con el siguiente test, cuando hayas terminado ejecuta la siguiente celda y te debería dar como resultado:\n",
    "\n",
    "```python\n",
    "[<keras.layers.core.dropout.Dropout at **************>,\n",
    " <keras.layers.core.dense.Dense at **************>,\n",
    " <keras.layers.core.dropout.Dropout at **************>,\n",
    " <keras.layers.core.dense.Dense at **************>]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7791ee-553f-4504-a848-33c3aa5bff1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca7791ee-553f-4504-a848-33c3aa5bff1c",
    "outputId": "ce9b165b-bd72-44bf-a821-f375bcdf529e"
   },
   "outputs": [],
   "source": [
    "model.layers[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40feae2a-ba27-4727-bfff-b955a79ae90b",
   "metadata": {
    "id": "40feae2a-ba27-4727-bfff-b955a79ae90b",
    "tags": []
   },
   "source": [
    "<a id=\"section4.5\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 7: entrenar el modelo</font>\n",
    "Una vez tenemos nuestro modelo listo para entrenar, vamos a configurar el entrenamiento y a entrenar nuesto modelo.\n",
    "\n",
    "En el entrenamiento utiliza:\n",
    "- Optimizador: Adam con learning rate de 0.001.\n",
    "- Función de coste: `sparse_categorical_crossentropy`.\n",
    "- Métricas: `accuracy`.\n",
    "- Epochs: `25`\n",
    "- validation_split: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04546993-e777-4df0-baf7-655ca8b9a1d3",
   "metadata": {
    "id": "04546993-e777-4df0-baf7-655ca8b9a1d3"
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22477af-0aa1-4633-892c-63641519e96b",
   "metadata": {
    "id": "e22477af-0aa1-4633-892c-63641519e96b",
    "tags": []
   },
   "source": [
    "<a id=\"section4.6\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 8: evaluar el modelo</font>\n",
    "Una vez entrenado el modelo usando _fine-tuning_ evalua el modelo usando el conjunto de test en la función `evaluate` y extráe conlcusiones de si el modelo tiene un buen rendimiento o no. Puedes visualizar como ha ido el entrenamiento usando una gráfica como hemos visto en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf5ab8-7070-42f9-af53-aae8c57665fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41a34f-3340-4841-ae76-12c1e0f7f97d",
   "metadata": {
    "id": "ee41a34f-3340-4841-ae76-12c1e0f7f97d",
    "tags": []
   },
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Red opcional</font>\n",
    "\n",
    "<a id=\"section5.1\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 7</font>\n",
    "\n",
    "En este ejercicio tienes vía libre para crear una red que tu creas que va a funcionar mejor. Puedes usar una red construida desde 0 que tu creas que funcionará mejor o puedes usar un modelo pre-entrenado entre los que puedes seleccionar en `tf._keras.applications` que puedes ver [aquí](https://www.tensorflow.org/api_docs/python/tf/keras/applications).\n",
    "\n",
    "Usa las capas que tú quieras y la configuración de entrenamiento que tu elijas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171831fa-171c-462d-a2eb-f2b579a16eea",
   "metadata": {
    "id": "171831fa-171c-462d-a2eb-f2b579a16eea"
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb600203-cecc-476d-815c-731d48f62780",
   "metadata": {
    "id": "bb600203-cecc-476d-815c-731d48f62780",
    "tags": []
   },
   "source": [
    "<a id=\"section6\"></a>\n",
    "# <font color=\"#004D7F\" size=5>¿Cuál es el mejor modelo?</font>\n",
    "\n",
    "<a id=\"section6.1\"></a>\n",
    "## <font color=\"#004D7F\" size=4>Ejercicio 8</font>\n",
    "\n",
    "Una vez realizado todos los experimentos anteriores, ¿qué modelo elegirías para desplegar en producción? ¿Por qué?\n",
    "\n",
    "Explica en breves palabras qué modelo eligirías para desplegar en producción y porqué. Compara cada experimento y extráe tus propias conclusiones.\n",
    "\n",
    "COMPLETAR: ESCRIBE AQUÍ TU TEXTO"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Caso-Practico.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
